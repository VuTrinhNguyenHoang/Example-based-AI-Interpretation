{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddeb8597",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc9975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce200246",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4c48a5",
   "metadata": {},
   "source": [
    "## Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9abcbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ..src.methods.compute_global import compute_sens, compute_ptb_classification as compute_ptb, compute_cw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e627893d",
   "metadata": {},
   "source": [
    "## Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da93c70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ..src.methods.compute_local import compute_llm_classification as compute_llm, compute_c_hp_classification as compute_c_hp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a45153",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7b0404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ..src.utils.extractor import extract_raw_features\n",
    "\n",
    "def save_history(dataset, history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss during Training')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history.get('accuracy', history.history.get('acc')), label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy during Training')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{dataset}_history.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5259f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build mlp\n",
    "def build_mlp(input_dim, hidden_units, num_classes):\n",
    "    inputs = tf.keras.Input(shape=(input_dim,), name=\"input\")\n",
    "    \n",
    "    x = tf.keras.layers.Dense(hidden_units, activation='relu',\n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(0.01), \n",
    "                              name='hidden')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax', name='output')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215138cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(url_train, url_test, n_neighbors):\n",
    "    df_train = pd.read_csv(url_train)\n",
    "    df_test = pd.read_csv(url_test)\n",
    "\n",
    "    print(df_train.shape, df_test.shape)\n",
    "\n",
    "    target = df_train.columns[-1]\n",
    "    X_train, X_test = df_train.drop(columns=[target]).values.astype(float), df_test.drop(columns=[target]).values.astype(float)\n",
    "    y_train, y_test = df_train[target].values, df_test[target].values\n",
    "    classes = np.unique(y_train)\n",
    "\n",
    "    # Train MLP\n",
    "    model = build_mlp(X_train.shape[1], 64, len(classes))\n",
    "    history = model.fit(X_train, y_train, epochs=30, batch_size=128, validation_split=0.1)\n",
    "    y_pred_test = model.predict(X_test).argmax(axis=1)\n",
    "    y_pred_train = model.predict(X_train).argmax(axis=1)\n",
    "    acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "    # Train k-NN*\n",
    "    X_train_raw = extract_raw_features(model, X_train)\n",
    "    X_test_raw = extract_raw_features(model, X_test)\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train_raw, y_pred_train)\n",
    "    y_pred_knn = knn.predict(X_test_raw)\n",
    "    acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "    agreement = accuracy_score(y_pred_test, y_pred_knn)\n",
    "\n",
    "    metric = {\n",
    "        'k_neighbors': n_neighbors,\n",
    "        'acc': acc,\n",
    "        'acc_k-NN*': acc_knn,\n",
    "        'agreement_k-NN*': agreement\n",
    "    }\n",
    "\n",
    "    # Train k-NN SENS\n",
    "    sens = compute_sens(model, X_train)\n",
    "    scaling = np.sqrt(np.abs(sens))\n",
    "    weights_train = X_train * scaling\n",
    "    weights_test = X_test * scaling\n",
    "\n",
    "    knn_weighted = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn_weighted.fit(weights_train, y_pred_train)\n",
    "    y_pred_weighted = knn_weighted.predict(weights_test)\n",
    "    acc_weighted = accuracy_score(y_test, y_pred_weighted)\n",
    "    agreement_weighted = accuracy_score(y_pred_test, y_pred_weighted)\n",
    "\n",
    "    metric['acc_sens'] = acc_weighted\n",
    "    metric['agreement_sens'] = agreement_weighted\n",
    "\n",
    "    # Train k-NN PTB\n",
    "    ptb = compute_ptb(model, X_train)\n",
    "    scaling = np.sqrt(np.abs(ptb))\n",
    "    weights_train = X_train * scaling\n",
    "    weights_test = X_test * scaling\n",
    "\n",
    "    knn_weighted = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn_weighted.fit(weights_train, y_pred_train)\n",
    "    y_pred_weighted = knn_weighted.predict(weights_test)\n",
    "    acc_weighted = accuracy_score(y_test, y_pred_weighted)\n",
    "    agreement_weighted = accuracy_score(y_pred_test, y_pred_weighted)\n",
    "\n",
    "    metric['acc_ptb'] = acc_weighted\n",
    "    metric['agreement_ptb'] = agreement_weighted\n",
    "\n",
    "    # Train k-NN CW\n",
    "    cw = compute_cw(model)\n",
    "    scaling = np.sqrt(np.abs(cw))\n",
    "    weights_train = X_train * scaling\n",
    "    weights_test = X_test * scaling\n",
    "\n",
    "    knn_weighted = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn_weighted.fit(weights_train, y_pred_train)\n",
    "    y_pred_weighted = knn_weighted.predict(weights_test)\n",
    "    acc_weighted = accuracy_score(y_test, y_pred_weighted)\n",
    "    agreement_weighted = accuracy_score(y_pred_test, y_pred_weighted)\n",
    "\n",
    "    metric['acc_cw'] = acc_weighted\n",
    "    metric['agreement_cw'] = agreement_weighted\n",
    "\n",
    "    # Train k-NN LLM\n",
    "    weights_train = np.array([compute_llm(model, x) for x in tqdm(X_train)])\n",
    "    weights_test = np.array([compute_llm(model, x) for x in tqdm(X_test)])\n",
    "\n",
    "    knn_weighted = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn_weighted.fit(weights_train, y_pred_train)\n",
    "    y_pred_weighted = knn_weighted.predict(weights_test)\n",
    "    acc_weighted = accuracy_score(y_test, y_pred_weighted)\n",
    "    agreement_weighted = accuracy_score(y_pred_test, y_pred_weighted)\n",
    "\n",
    "    metric['acc_llm'] = acc_weighted\n",
    "    metric['agreement_llm'] = agreement_weighted\n",
    "\n",
    "    # Train k-NN C-HP\n",
    "    weights_train = np.array([compute_c_hp(model, x) for x in tqdm(X_train)])\n",
    "    weights_test = np.array([compute_c_hp(model, x) for x in tqdm(X_test)])\n",
    "\n",
    "    knn_weighted = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn_weighted.fit(weights_train, y_pred_train)\n",
    "    y_pred_weighted = knn_weighted.predict(weights_test)\n",
    "    acc_weighted = accuracy_score(y_test, y_pred_weighted)\n",
    "    agreement_weighted = accuracy_score(y_pred_test, y_pred_weighted)\n",
    "\n",
    "    metric['acc_chp'] = acc_weighted\n",
    "    metric['agreement_chp'] = agreement_weighted\n",
    "\n",
    "    return model, history, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf3d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = ['bank_marketing', 'breast_cancer', 'nursery']\n",
    "metrics = []\n",
    "for n_neighbors in range(1, 6):\n",
    "    for dataset in dataset_names:\n",
    "        url_train = f'/kaggle/input/mlp-cbr-classification/{dataset}_train.csv'\n",
    "        url_test = f'/kaggle/input/mlp-cbr-classification/{dataset}_test.csv'\n",
    "    \n",
    "        model, history, metric = experiment(url_train, url_test, n_neighbors)\n",
    "        \n",
    "        save_history(dataset, history)\n",
    "        metric['Dataset'] = dataset\n",
    "        metrics.append(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546efb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(metrics)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
