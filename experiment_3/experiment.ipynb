{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2347d71f",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d3fbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers, Input\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33af182",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e369b0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_name, data_fraction=1):\n",
    "    if dataset_name == 'mnist':\n",
    "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "        x_train = np.expand_dims(x_train, -1)\n",
    "        x_test = np.expand_dims(x_test, -1)\n",
    "        num_channels = 1\n",
    "        input_shape = (28, 28, num_channels)\n",
    "        num_classes = 10\n",
    "    elif dataset_name == 'mnist-fashion':\n",
    "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "        x_train = np.expand_dims(x_train, -1)\n",
    "        x_test = np.expand_dims(x_test, -1)\n",
    "        num_channels = 1\n",
    "        input_shape = (28, 28, num_channels)\n",
    "        num_classes = 10\n",
    "    elif dataset_name == 'cifar-10':\n",
    "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "        y_train = y_train.flatten()\n",
    "        y_test = y_test.flatten()\n",
    "        num_channels = 3\n",
    "        input_shape = (32, 32, num_channels)\n",
    "        num_classes = 10\n",
    "    else:\n",
    "        raise ValueError(f\"Don't support Dataset {dataset_name}\")\n",
    "\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "\n",
    "    if data_fraction < 1:\n",
    "        num_train = len(x_train)\n",
    "        num_test = len(x_test)\n",
    "        train_indices = np.random.choice(num_train, int(num_train * data_fraction), replace=False)\n",
    "        test_indices = np.random.choice(num_test, int(num_test * data_fraction), replace=False)\n",
    "        x_train = x_train[train_indices]\n",
    "        y_train = y_train[train_indices]\n",
    "        x_test = x_test[test_indices]\n",
    "        y_test = y_test[test_indices]\n",
    "    \n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=.2, random_state=42)\n",
    "\n",
    "    return (x_train, y_train), (x_val, y_val), (x_test, y_test), num_channels, input_shape, num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cadc7b",
   "metadata": {},
   "source": [
    "# Build CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed02717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(input_shape, num_classes, model_name):\n",
    "    inputs = Input(shape=input_shape, name='input')\n",
    "    x = Conv2D(32, (3, 3), activation='relu', name='conv1')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', name='conv2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', name='conv3')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', name='conv4')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), activation='relu', name='conv5')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    x = Flatten()(x) if model_name == 'flatten' else GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu', kernel_regularizer=regularizers.l2(1e-3))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax', name='output')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2177f3cd",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b4feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_c_hp(model, x, last_conv_layer_name):\n",
    "    x_tensor = tf.convert_to_tensor(x[None, ...], dtype=tf.float32)\n",
    "    \n",
    "    grad_model = tf.keras.models.Model(\n",
    "        inputs=model.inputs,\n",
    "        outputs=[model.get_layer(last_conv_layer_name).output, model.outputs]\n",
    "    )\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(x_tensor)\n",
    "        predicted_class = np.argmax(predictions[0].numpy())\n",
    "        \n",
    "        class_output = predictions[0][0][predicted_class]\n",
    "    \n",
    "    gradients = tape.gradient(class_output, conv_outputs)\n",
    "    if gradients is None:\n",
    "        raise ValueError(\"Gradients are None. Check the connections between layers in the model!\")\n",
    "    \n",
    "    c_hp = (gradients * conv_outputs)[0]\n",
    "    \n",
    "    c_hp_flat = tf.reshape(c_hp, [-1])\n",
    "    return c_hp_flat.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00a3036",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581fe855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(model, x, y, labels, num_images=10):\n",
    "    pred = model.predict(x).argmax(axis=1)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(x[i])\n",
    "        true_label = labels[y[i]]\n",
    "        pred_label = labels[pred[i]]\n",
    "        color = 'green' if true_label == pred_label else 'red'\n",
    "        plt.title(f\"True: {true_label}\\nPred: {pred_label}\", color=color) \n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def twin_system_test(dataset_name, model_name, cnn, knn, x_train, y_train, x_test, y_test, labels, num_channels):\n",
    "    rand_idx = np.random.randint(0, x_test.shape[0])\n",
    "    test_img = x_test[rand_idx]\n",
    "    cnn_pred = np.argmax(cnn.predict(test_img[None, ...]), axis=1)[0]\n",
    "\n",
    "    chp = compute_c_hp(cnn, test_img, 'conv5')\n",
    "    knn_index = knn.kneighbors(chp.reshape(1, -1), n_neighbors=1, return_distance=False)[0][0]\n",
    "    retrieved_img = x_train[knn_index]\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(np.squeeze(test_img), cmap='gray' if num_channels == 1 else None)\n",
    "    color = 'green' if y_test[rand_idx] == cnn_pred else 'red'\n",
    "    plt.title(f'Test Image\\nCNN predicted: {labels[cnn_pred]}\\nTrue: {labels[y_test[rand_idx]]}', color=color)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(np.squeeze(retrieved_img), cmap='gray' if num_channels == 1 else None)\n",
    "    plt.title(f'Nearest Image\\nLabels: {labels[y_train[knn_index]]}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'twin_system_{model_name}_{dataset_name}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58630f16",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca3461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_name, dataset_name, model, x_train, y_train, x_valid, y_valid, epochs=50, batch_size=64):\n",
    "    history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_valid, y_valid))\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validtion Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(f'{dataset_name}_{model_name}_history.png')\n",
    "    plt.show()\n",
    "\n",
    "def experiment(dataset_name, model_name, labels, epochs=50, data_fraction=1):\n",
    "    (x_train, y_train), (x_valid, y_valid), (x_test, y_test), num_channels, input_shape, num_classes = load_data(dataset_name, data_fraction)\n",
    "    model = build_cnn(input_shape, num_classes, model_name)\n",
    "\n",
    "    # Train CNN\n",
    "    train(model_name, dataset_name, model, x_train, y_train, x_valid, y_valid, epochs=epochs)\n",
    "    model.save(f'{model_name}_{dataset_name}.h5')\n",
    "    y_train_pred = model.predict(x_train).argmax(axis=1)\n",
    "    y_test_pred = model.predict(x_test).argmax(axis=1)\n",
    "    acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    print(f'Accuracy {model_name} with {dataset_name}: {acc}')\n",
    "\n",
    "    # Plot random 10 image\n",
    "    indices = np.random.choice(len(x_test), 10, replace=False)\n",
    "    plot_predictions(model, x_test[indices], y_test[indices], labels)\n",
    "\n",
    "    # Train k-NN*\n",
    "    feature_extractor = tf.keras.models.Model(\n",
    "        inputs=model.inputs,\n",
    "        outputs=[model.get_layer('conv5').output, model.outputs]\n",
    "    )\n",
    "    x_train_features = feature_extractor.predict(x_train)[0].reshape(len(x_train), -1)\n",
    "    x_test_features = feature_extractor.predict(x_test)[0].reshape(len(x_test), -1)\n",
    "    \n",
    "    knn_star = KNeighborsClassifier(n_neighbors=1)\n",
    "    knn_star.fit(x_train_features, y_train_pred)\n",
    "    y_test_knn_star = knn_star.predict(x_test_features)\n",
    "\n",
    "    accuracy_star = accuracy_score(y_test, y_test_knn_star)\n",
    "    agreement_star = accuracy_score(y_test_pred, y_test_knn_star)\n",
    "    \n",
    "    print(\"Agreement between CNN and k-NN (raw features):\", agreement_star)\n",
    "    print(\"Accuracy of k-NN (raw features) vs true labels:\", accuracy_star)\n",
    "    \n",
    "    # Train k-NN with C-HP\n",
    "    C_train = np.array([compute_c_hp(model, x, 'conv5') for x in tqdm(x_train)])\n",
    "    C_test = np.array([compute_c_hp(model, x, 'conv5') for x in tqdm(x_test)])\n",
    "    knn_chp = KNeighborsClassifier(n_neighbors=1)\n",
    "    knn_chp.fit(C_train, y_train_pred)\n",
    "    y_test_knn_chp = knn_chp.predict(C_test)\n",
    "\n",
    "    accuracy_chp = accuracy_score(y_test, y_test_knn_chp)\n",
    "    agreement_chp = accuracy_score(y_test_pred, y_test_knn_chp)\n",
    "\n",
    "    print('Agreement between CNN and k-NN C-HP:', agreement_chp)\n",
    "    print('Accuracy of k-NN C-HP vs true labels:', accuracy_chp)\n",
    "\n",
    "    # Test Twin-System\n",
    "    twin_system_test(dataset_name, model_name, model, knn_chp, x_train, y_train, x_test, y_test, labels, num_channels)\n",
    "\n",
    "    return {\n",
    "        'Dataset': dataset_name,\n",
    "        'acc': acc,\n",
    "        'acc k-NN*': accuracy_star,\n",
    "        'agreement k-NN*': agreement_star,\n",
    "        'acc C-HP': accuracy_chp,\n",
    "        'agreement C-HP': agreement_chp\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd368619",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    'mnist': [str(i) for i in range(10)],\n",
    "    'mnist-fashion': ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'],\n",
    "    'cifar-10': ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "}\n",
    "\n",
    "for model in ['gap', 'flatten']:\n",
    "    results = []\n",
    "    for dataset in ['mnist', 'mnist-fashion', 'cifar-10']:\n",
    "        results.append(experiment(dataset, model, labels[dataset], 50, 0.5))\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    df.to_csv(f'results_{model}_{dataset}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
