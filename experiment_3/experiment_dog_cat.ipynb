{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5e48d75",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee62322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import joblib\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Tensorflow version:', tf.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Using cuda devices (GPU)' if gpus else 'GPU not available, using CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e33dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path and parameters\n",
    "DATADIR = '/kaggle/input/cat-dog-images-for-classification/cat_dog'\n",
    "H, W = 224, 224\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2fd69d",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/cat-dog-images-for-classification/cat_dog.csv')\n",
    "df['filenames'] = df['image']\n",
    "df['labels'] = df['labels'].map(lambda x: 'dog' if x == 1 else 'cat')\n",
    "df.drop(columns=['image'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9b190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ca1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=SEED, stratify=df['labels'])\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=1/3, random_state=SEED, stratify=temp_df['labels'])\n",
    "train_df.sample(frac=1, random_state=SEED)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "print('Train size:', len(train_df))\n",
    "print('Validation size:', len(valid_df))\n",
    "print('Test size:', len(test_df))\n",
    "\n",
    "train_df.to_csv('train.csv')\n",
    "valid_df.to_csv('valid.csv')\n",
    "test_df.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d817dd27",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e75b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs = list(df[df.labels == 'dog'].filenames)\n",
    "cats = list(df[df.labels == 'cat'].filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6ffb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_side(img, side_type, n=5):\n",
    "    h, w, c = img.shape\n",
    "    if side_type == 'horizontal':\n",
    "        return np.ones((h, n, c))\n",
    "    return np.ones((n, w, c))\n",
    "\n",
    "def show_gallery(data, n, title):\n",
    "    images = []\n",
    "    vertical_images = []\n",
    "\n",
    "    for i in range(n * n):\n",
    "        img = load_img(os.path.join(DATADIR, data[i]), target_size=(W, H))\n",
    "        img = img_to_array(img)\n",
    "        hside = get_side(img, side_type='horizontal')\n",
    "        images.append(img)\n",
    "        images.append(hside)\n",
    "\n",
    "        if (i + 1) % n == 0:\n",
    "            himage = np.hstack((images))\n",
    "            vside = get_side(himage, side_type=\"vertical\")\n",
    "            vertical_images.append(himage)\n",
    "            vertical_images.append(vside)\n",
    "            \n",
    "            images = []\n",
    "\n",
    "    gallery = np.vstack((vertical_images))\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(gallery.astype(np.uint8))\n",
    "    plt.savefig(f'gallery_{title}.jpg', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97293e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gallery(dogs, n=10, title='dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4db569",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gallery(cats, n=10, title='cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf18847",
   "metadata": {},
   "source": [
    "# GradCAM & GuidedGradCAM class define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bc15e2",
   "metadata": {},
   "source": [
    "## GuidedBackprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf794ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def guidedRelu(x):\n",
    "    def grad(dy):\n",
    "        return tf.cast(dy > 0, 'float32') * tf.cast(x > 0, 'float32') * dy\n",
    "    return tf.nn.relu(x), grad\n",
    "\n",
    "class GuidedBackprop:\n",
    "    def __init__(self,model, layerName=None):\n",
    "        self.model = model\n",
    "        self.layerName = layerName\n",
    "        self.gbModel = self.build_guided_model()\n",
    "        \n",
    "        if self.layerName == None:\n",
    "            self.layerName = self.find_target_layer()\n",
    "\n",
    "    def find_target_layer(self):\n",
    "        for layer in reversed(self.model.layers):\n",
    "            if len(layer.output_shape) == 4:\n",
    "                return layer.name\n",
    "        raise ValueError(\"Could not find 4D layer. Cannot apply Guided Backpropagation\")\n",
    "\n",
    "    def build_guided_model(self):\n",
    "        gbModel = Model(\n",
    "            inputs = [self.model.inputs],\n",
    "            outputs = [self.model.get_layer(self.layerName).output]\n",
    "        )\n",
    "        layer_dict = [layer for layer in gbModel.layers[1:] if hasattr(layer, \"activation\")]\n",
    "        for layer in layer_dict:\n",
    "            if layer.activation == tf.keras.activations.relu:\n",
    "                layer.activation = guidedRelu\n",
    "        \n",
    "        return gbModel\n",
    "    \n",
    "    def guided_backprop(self, images, upsample_size):\n",
    "        \"\"\"Guided Backpropagation method for visualizing input saliency.\"\"\"\n",
    "        with tf.GradientTape() as tape:\n",
    "            inputs = tf.cast(images, tf.float32)\n",
    "            tape.watch(inputs)\n",
    "            outputs = self.gbModel(inputs)\n",
    "\n",
    "        grads = tape.gradient(outputs, inputs)[0]\n",
    "\n",
    "        saliency = cv2.resize(np.asarray(grads), upsample_size)\n",
    "\n",
    "        return saliency\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.25\n",
    "    x = x.copy()\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + K.epsilon())\n",
    "    x *= 0.25\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee6c560",
   "metadata": {},
   "source": [
    "## GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3733d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCAM:\n",
    "    def __init__(self, model, layerName=None):\n",
    "        \"\"\"\n",
    "        model: pre-softmax layer (logit layer)\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.layerName = layerName\n",
    "            \n",
    "        if self.layerName == None:\n",
    "            self.layerName = self.find_target_layer()\n",
    "    \n",
    "    def find_target_layer(self):\n",
    "        for layer in reversed(self.model.layers):\n",
    "            if len(layer.output_shape) == 4:\n",
    "                return layer.name\n",
    "        raise ValueError(\"Could not find 4D layer. Cannot apply GradCAM\")\n",
    "            \n",
    "    def compute_heatmap(self, image, classIdx, upsample_size, eps=1e-5):\n",
    "        gradModel = Model(\n",
    "            inputs = [self.model.inputs],\n",
    "            outputs = [self.model.get_layer(self.layerName).output, self.model.outputs]\n",
    "        )\n",
    "        # record operations for automatic differentiation\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            inputs = tf.cast(image, tf.float32)\n",
    "            (convOuts, preds) = gradModel(inputs) # preds after softmax\n",
    "            loss = preds[0][:, classIdx]\n",
    "        \n",
    "        # compute gradients with automatic differentiation\n",
    "        grads = tape.gradient(loss, convOuts)\n",
    "        # discard batch\n",
    "        convOuts = convOuts[0]\n",
    "        grads = grads[0]\n",
    "        norm_grads = tf.divide(grads, tf.reduce_mean(tf.square(grads)) + tf.constant(eps))\n",
    "        \n",
    "        # compute weights\n",
    "        weights = tf.reduce_mean(norm_grads, axis=(0,1))\n",
    "        cam = tf.reduce_sum(tf.multiply(weights, convOuts), axis=-1)\n",
    "        \n",
    "        # Apply reLU\n",
    "        cam = np.maximum(cam, 0)\n",
    "        cam = cam/np.max(cam)\n",
    "        cam = cv2.resize(cam, upsample_size,interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # convert to 3D\n",
    "        cam3 = np.expand_dims(cam, axis=2)\n",
    "        cam3 = np.tile(cam3, [1,1,3])\n",
    "        \n",
    "        return cam3\n",
    "    \n",
    "def overlay_gradCAM(img, cam3):\n",
    "    cam3 = np.uint8(255 * cam3)\n",
    "    cam3 = cv2.applyColorMap(cam3, cv2.COLORMAP_JET)\n",
    "    \n",
    "    new_img = 0.3 * cam3 + 0.5 * img\n",
    "    \n",
    "    return (new_img * 255.0 / new_img.max()).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc6d482",
   "metadata": {},
   "source": [
    "# Visualization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c509c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_gradCAMs(model, gradCAM, GuidedBP, im_ls, n, classes):\n",
    "    \"\"\"\n",
    "    model: softmax layer\n",
    "    \"\"\"\n",
    "\n",
    "    plt.subplots(figsize=(30, 10 * n))\n",
    "    k = 1\n",
    "    \n",
    "    for i in range(n):\n",
    "        img = cv2.imread(os.path.join(DATADIR, im_ls[i]))\n",
    "        upsample_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "        # Show original image\n",
    "        plt.subplot(n, 3, k)\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Filename: {im_ls[i]}', fontsize=20)\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Show overlayed Grad\n",
    "        plt.subplot(n, 3, k + 1)\n",
    "        im = img_to_array(load_img(os.path.join(DATADIR, im_ls[i]), target_size=(W, H)))\n",
    "        x = np.expand_dims(im, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        preds = model.predict(x)\n",
    "        idx = preds.argmax()\n",
    "\n",
    "        cam3 = gradCAM.compute_heatmap(image=x, classIdx=idx, upsample_size=upsample_size)\n",
    "        new_img = overlay_gradCAM(img, cam3)\n",
    "        new_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(new_img)\n",
    "        plt.title(f'GradCAM - Pred: {classes[idx]}. Prob: {preds.max()}', fontsize=20)\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Show Guided GradCAM\n",
    "        plt.subplot(n, 3, k + 2)\n",
    "        gb = GuidedBP.guided_backprop(x, upsample_size)\n",
    "        guided_gradcam = deprocess_image(gb * cam3)\n",
    "        guided_gradcam = cv2.cvtColor(guided_gradcam, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(guided_gradcam)\n",
    "        plt.title(\"Guided GradCAM\", fontsize=20)\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        k += 3\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4430fa64",
   "metadata": {},
   "source": [
    "# Re-Train output layer of Resnet model on dogs and cats data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0562db",
   "metadata": {},
   "source": [
    "# Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cb9566",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    DATADIR,\n",
    "    x_col='filenames',\n",
    "    y_col='labels',\n",
    "    target_size=(W, H),\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17468bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "valid_generator = valid_datagen.flow_from_dataframe(\n",
    "    valid_df,\n",
    "    DATADIR,\n",
    "    x_col='filenames',\n",
    "    y_col='labels',\n",
    "    target_size=(W, H),\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b0ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    DATADIR,\n",
    "    x_col='filenames',\n",
    "    y_col='labels',\n",
    "    target_size=(W, H),\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08231d8d",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82142d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet50V2(weights='imagenet', pooling='avg', include_top=False)\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "fc1 = Dense(128)(resnet.layers[-1].output)\n",
    "fc2 = Dense(128, name='dense_feature')(fc1)\n",
    "dropout = Dropout(0.5)(fc2)\n",
    "outputs = Dense(2, activation='softmax')(dropout)\n",
    "\n",
    "model = Model(inputs=resnet.input, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1406239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(learning_rate=1e-3, weight_decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed74006",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c07b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('resnet50v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5182cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(history.history['loss'], label='Train') \n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Validtion')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('history.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccea894c",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427bec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('/kaggle/input/models/tensorflow2/default/2/resnet50v2.h5')\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7417c8f",
   "metadata": {},
   "source": [
    "# Observe GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821f51de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logit = Model(model.input, model.layers[-1].output)\n",
    "fctrained_gradCAM = GradCAM(model_logit, layerName='conv5_block3_out')\n",
    "fctrained_guidedBP = GuidedBackprop(model, layerName='conv5_block3_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1125b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_generator)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f84b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_df.copy()\n",
    "results['predict'] = y_pred\n",
    "true_dogs = list(results[(results.labels == 'dog') & (results.predict == 1)].filenames)\n",
    "true_cats = list(results[(results.labels == 'cat') & (results.predict == 0)].filenames)\n",
    "wrong_class = [x for x in results.filenames if x not in (true_dogs + true_cats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wrong_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad677553",
   "metadata": {},
   "source": [
    "## Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6572e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gradCAMs(model, fctrained_gradCAM, fctrained_guidedBP, true_dogs, n=5, classes={0: 'cat', 1: 'dog'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327fdd34",
   "metadata": {},
   "source": [
    "## Cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0548a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gradCAMs(model, fctrained_gradCAM, fctrained_guidedBP, true_cats, n=5, classes={0: 'cat', 1: 'dog'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d836d5",
   "metadata": {},
   "source": [
    "## Wrong classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ad6a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gradCAMs(model, fctrained_gradCAM, fctrained_guidedBP, wrong_class, n=5, classes={0: 'cat', 1: 'dog'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a13a8e6",
   "metadata": {},
   "source": [
    "# Feature Extract (COLE Hamard Product - C-HP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb99b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self, model, layerName=None):\n",
    "        \"\"\"\n",
    "        model: pre-softmax layer (logit layer)\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.layerName = layerName\n",
    "            \n",
    "        if self.layerName == None:\n",
    "            self.layerName = self.find_target_layer()\n",
    "    \n",
    "    def find_target_layer(self):\n",
    "        for layer in reversed(self.model.layers):\n",
    "            if len(layer.output_shape) == 4:\n",
    "                return layer.name\n",
    "        raise ValueError(\"Could not find 4D layer. Cannot apply GradCAM\")\n",
    "            \n",
    "    def compute_c_hp(self, image, classIdx):\n",
    "        gradModel = Model(\n",
    "            inputs = [self.model.inputs],\n",
    "            outputs = [self.model.get_layer(self.layerName).output, self.model.outputs]\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            inputs = tf.cast(image, tf.float32)\n",
    "            (convOuts, preds) = gradModel(inputs) \n",
    "            loss = preds[0][:, classIdx]\n",
    "        \n",
    "        grads = tape.gradient(loss, convOuts)\n",
    "        if grads is None:\n",
    "            raise ValueError(\"Gradients is None\")\n",
    "        \n",
    "        c_hp = (grads * convOuts)[0]\n",
    "        \n",
    "        c_hp_flat = tf.reshape(c_hp, [-1])\n",
    "        c_hp_flat = tf.math.l2_normalize(c_hp_flat)\n",
    "        return c_hp_flat.numpy()\n",
    "\n",
    "def get_chp_on_dataframe(extractor, df):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for path in tqdm(df.filenames):\n",
    "\n",
    "        img = img_to_array(load_img(os.path.join(DATADIR, path), target_size=(W, H)))\n",
    "        x = np.expand_dims(img, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        preds = model.predict(x, verbose=0)\n",
    "        idx = preds.argmax()\n",
    "        \n",
    "        c_hp = extractor.compute_c_hp(image=x, classIdx=idx)\n",
    "        features.append(c_hp)\n",
    "        labels.append('dog' if idx == 1 else 'cat')\n",
    "\n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba44ae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = FeatureExtractor(model, layerName='dense_feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), y_train_true = get_chp_on_dataframe(extractor, train_df), train_df.labels\n",
    "(X_test, y_test), y_test_true = get_chp_on_dataframe(extractor, test_df), test_df.labels\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d310e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test_true, y_pred)) # Accuracy with true labels\n",
    "print('Agreement:', accuracy_score(y_test, y_pred)) # Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b661799",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(knn, 'knn_chp_norm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfb1573",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_idx = np.random.randint(0, len(test_df))\n",
    "path = test_df.filenames[rand_idx]\n",
    "# path = 'dog.6131.jpg'\n",
    "classes = {0: 'cat', 1: 'dog'}\n",
    "\n",
    "img = cv2.imread(os.path.join(DATADIR, path))\n",
    "upsample_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "plt.subplots(figsize=(30, 20))\n",
    "\n",
    "# Show original image\n",
    "plt.subplot(231)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f'Filename: {path}', fontsize=20)\n",
    "plt.axis('off')\n",
    "\n",
    "# Show overlayed Grad\n",
    "plt.subplot(232)\n",
    "im = img_to_array(load_img(os.path.join(DATADIR, path), target_size=(W, H)))\n",
    "x = np.expand_dims(im, axis=0)\n",
    "x = preprocess_input(x)\n",
    "preds = model.predict(x)\n",
    "idx = preds.argmax()\n",
    "\n",
    "cam3 = fctrained_gradCAM.compute_heatmap(image=x, classIdx=idx, upsample_size=upsample_size)\n",
    "new_img = overlay_gradCAM(img, cam3)\n",
    "new_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(new_img)\n",
    "plt.title(f'GradCAM - Pred: {classes[idx]}. Prob: {preds.max()}', fontsize=20)\n",
    "plt.axis('off')\n",
    "\n",
    "# Show Guided GradCAM\n",
    "plt.subplot(233)\n",
    "gb = fctrained_guidedBP.guided_backprop(x, upsample_size)\n",
    "guided_gradcam = deprocess_image(gb * cam3)\n",
    "guided_gradcam = cv2.cvtColor(guided_gradcam, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(guided_gradcam)\n",
    "plt.title(\"Guided GradCAM\", fontsize=20)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "######################### Retrieved ##################################\n",
    "\n",
    "c_hp = extractor.compute_c_hp(image=x, classIdx=idx)\n",
    "knn_index = knn.kneighbors(c_hp.reshape(1, -1), n_neighbors=1, return_distance=False)[0, 0]\n",
    "c_hp_retrieved = knn._fit_X[knn_index]\n",
    "retrieved_path = train_df.filenames[knn_index]\n",
    "retrieved_label = train_df.labels[knn_index]\n",
    "\n",
    "img = cv2.imread(os.path.join(DATADIR, retrieved_path))\n",
    "upsample_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# Show retrieved image\n",
    "plt.subplot(234)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(f'Retrieved Filename: {retrieved_path}', fontsize=20)\n",
    "plt.axis('off')\n",
    "\n",
    "# Show overlayed Grad\n",
    "plt.subplot(235)\n",
    "im = img_to_array(load_img(os.path.join(DATADIR, retrieved_path), target_size=(W, H)))\n",
    "x = np.expand_dims(im, axis=0)\n",
    "x = preprocess_input(x)\n",
    "preds = model.predict(x)\n",
    "idx = preds.argmax()\n",
    "\n",
    "cam3 = fctrained_gradCAM.compute_heatmap(image=x, classIdx=idx, upsample_size=upsample_size)\n",
    "new_img = overlay_gradCAM(img, cam3)\n",
    "new_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(new_img)\n",
    "plt.title(f'GradCAM - Pred: {classes[idx]}. Prob: {preds.max()}', fontsize=20)\n",
    "plt.axis('off')\n",
    "\n",
    "# Show Guided GradCAM\n",
    "plt.subplot(236)\n",
    "gb = fctrained_guidedBP.guided_backprop(x, upsample_size)\n",
    "guided_gradcam = deprocess_image(gb * cam3)\n",
    "guided_gradcam = cv2.cvtColor(guided_gradcam, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(guided_gradcam)\n",
    "plt.title(\"Guided GradCAM\", fontsize=20)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
